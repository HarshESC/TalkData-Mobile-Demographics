{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8b/0ofNhqettkGg62818q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshESC/TalkData-Mobile-Demographics/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00cXoM1C7SZM",
        "outputId": "1d559c2b-bb31-4464-8d5b-5e3729cf4357"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/\"\n",
        "%cd \"/content/gdrive/My Drive/Final Capstone\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import (\n",
        "    Activation,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Final Capstone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-v5hZv8Ujo"
      },
      "source": [
        "master_df = pd.read_csv(\"master_clean_2.csv\")\n",
        "X = master_df.drop(columns=[\"num_group\"])\n",
        "y = master_df[\"num_group\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=13, stratify=y\n",
        ")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "C8cQacRX8tkQ",
        "outputId": "f7f79a9f-ed86-4930-8b92-4922c16c56a4"
      },
      "source": [
        "X_test\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>device_id</th>\n",
              "      <th>label_id_x</th>\n",
              "      <th>download_id</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>405</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>704</th>\n",
              "      <th>713</th>\n",
              "      <th>730</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>761</th>\n",
              "      <th>775</th>\n",
              "      <th>777</th>\n",
              "      <th>779</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>787</th>\n",
              "      <th>959</th>\n",
              "      <th>960</th>\n",
              "      <th>1007</th>\n",
              "      <th>english_phone_brand_coolpad</th>\n",
              "      <th>english_phone_brand_huawei</th>\n",
              "      <th>english_phone_brand_lshi</th>\n",
              "      <th>english_phone_brand_meizu</th>\n",
              "      <th>english_phone_brand_oppo</th>\n",
              "      <th>english_phone_brand_samsung</th>\n",
              "      <th>english_phone_brand_xiaomi</th>\n",
              "      <th>device_model_Galaxy Note 3</th>\n",
              "      <th>device_model_MI 4</th>\n",
              "      <th>device_model_MX4</th>\n",
              "      <th>device_model_MX5</th>\n",
              "      <th>device_model_Mate 7</th>\n",
              "      <th>device_model_R7s</th>\n",
              "      <th>device_model_U3</th>\n",
              "      <th>device_model_note顶配版</th>\n",
              "      <th>device_model_小米note</th>\n",
              "      <th>device_model_荣耀6</th>\n",
              "      <th>device_model_荣耀6 Plus</th>\n",
              "      <th>device_model_超级手机1 Pro</th>\n",
              "      <th>device_model_魅蓝metal</th>\n",
              "      <th>device_model_麦芒4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3972</th>\n",
              "      <td>331345</td>\n",
              "      <td>-1633912816187681087</td>\n",
              "      <td>1</td>\n",
              "      <td>-9170266620213363189</td>\n",
              "      <td>787</td>\n",
              "      <td>7642564637308507340</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34708</th>\n",
              "      <td>3137225</td>\n",
              "      <td>4348659952760821294</td>\n",
              "      <td>1</td>\n",
              "      <td>-1665198983206396063</td>\n",
              "      <td>548</td>\n",
              "      <td>2683460969554425231</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>144053</td>\n",
              "      <td>-8103714741965524240</td>\n",
              "      <td>0</td>\n",
              "      <td>2596032420261205364</td>\n",
              "      <td>787</td>\n",
              "      <td>-5507682321704318876</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8021</th>\n",
              "      <td>663472</td>\n",
              "      <td>-1200607960388315089</td>\n",
              "      <td>0</td>\n",
              "      <td>5499466531572133131</td>\n",
              "      <td>713</td>\n",
              "      <td>4298858571183818042</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10225</th>\n",
              "      <td>913759</td>\n",
              "      <td>33792862810792679</td>\n",
              "      <td>0</td>\n",
              "      <td>1734050676638523012</td>\n",
              "      <td>713</td>\n",
              "      <td>1767843539449315691</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34832</th>\n",
              "      <td>3148380</td>\n",
              "      <td>-9050100410106163077</td>\n",
              "      <td>0</td>\n",
              "      <td>-1544445963999571951</td>\n",
              "      <td>787</td>\n",
              "      <td>7852197699603816588</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>45155</td>\n",
              "      <td>7316250158002095415</td>\n",
              "      <td>0</td>\n",
              "      <td>-4483258470894206861</td>\n",
              "      <td>757</td>\n",
              "      <td>2832991687107888554</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14095</th>\n",
              "      <td>1165984</td>\n",
              "      <td>-1073344577746533072</td>\n",
              "      <td>0</td>\n",
              "      <td>5499466531572133131</td>\n",
              "      <td>730</td>\n",
              "      <td>4426121953825600059</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23610</th>\n",
              "      <td>2117736</td>\n",
              "      <td>-974457023668610292</td>\n",
              "      <td>0</td>\n",
              "      <td>-6335083146238767307</td>\n",
              "      <td>761</td>\n",
              "      <td>-7309540169907377599</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12927</th>\n",
              "      <td>1077613</td>\n",
              "      <td>-7509752927626140732</td>\n",
              "      <td>0</td>\n",
              "      <td>5499466531572133131</td>\n",
              "      <td>1007</td>\n",
              "      <td>-2010286396054007601</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7208 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       event_id               app_id  ...  device_model_魅蓝metal  device_model_麦芒4\n",
              "3972     331345 -1633912816187681087  ...                     0                 0\n",
              "34708   3137225  4348659952760821294  ...                     0                 0\n",
              "1279     144053 -8103714741965524240  ...                     0                 0\n",
              "8021     663472 -1200607960388315089  ...                     0                 0\n",
              "10225    913759    33792862810792679  ...                     0                 1\n",
              "...         ...                  ...  ...                   ...               ...\n",
              "34832   3148380 -9050100410106163077  ...                     0                 0\n",
              "471       45155  7316250158002095415  ...                     0                 0\n",
              "14095   1165984 -1073344577746533072  ...                     0                 0\n",
              "23610   2117736  -974457023668610292  ...                     0                 0\n",
              "12927   1077613 -7509752927626140732  ...                     0                 0\n",
              "\n",
              "[7208 rows x 47 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy29E6s58qFw",
        "outputId": "08c00bce-2c1c-4208-ce8d-c62f444a4cb5"
      },
      "source": [
        "y_test\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3972      5\n",
              "34708     5\n",
              "1279     10\n",
              "8021      5\n",
              "10225     5\n",
              "         ..\n",
              "34832     4\n",
              "471       1\n",
              "14095     5\n",
              "23610     3\n",
              "12927     5\n",
              "Name: num_group, Length: 7208, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JmSf11G8tOw",
        "outputId": "74fbb87a-a135-4397-cd8d-9779c6278deb"
      },
      "source": [
        "master_df[\"num_group\"].value_counts()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5     11416\n",
              "4      9521\n",
              "3      5955\n",
              "10     2862\n",
              "9      2060\n",
              "11     1697\n",
              "1      1596\n",
              "2       585\n",
              "0       345\n",
              "Name: num_group, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqxmmCTf9FMp"
      },
      "source": [
        "# Output_dim = 12 because there are 12 different age/gender groups\n",
        "output_dim = 12\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNKISkde9JS4"
      },
      "source": [
        "X_train_np = X_train.to_numpy()\n",
        "X_test_np = X_test.to_numpy()\n",
        "y_train = to_categorical(y_train, output_dim)\n",
        "y_test = to_categorical(y_test, output_dim)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1zuYICnvZc"
      },
      "source": [
        "# 128 Batch, 20 Epocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5WNq59h9QcI"
      },
      "source": [
        "# 3 Layer RELU Model with ADAM Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY_ZKoNq9Nnx"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUmZQDJ49VGY"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATVPSjH09VI4",
        "outputId": "34c31e5c-2560-4b6e-8d5c-c321bc01d7f1"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 63753523879215104.0000 - accuracy: 0.3068\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 17990277973147648.0000 - accuracy: 0.3262\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 14696937852764160.0000 - accuracy: 0.3436\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 13327521890172928.0000 - accuracy: 0.3450\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 14020176634707968.0000 - accuracy: 0.3440\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 11817452191088640.0000 - accuracy: 0.3556\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 10805636279304192.0000 - accuracy: 0.3545\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 11359784770994176.0000 - accuracy: 0.3527\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 11780001150009344.0000 - accuracy: 0.3508\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 9802317960314880.0000 - accuracy: 0.3590\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 9539969546715136.0000 - accuracy: 0.3609\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 8232000070615040.0000 - accuracy: 0.3662\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 8489734078726144.0000 - accuracy: 0.3621\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 7690104046878720.0000 - accuracy: 0.3682\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 7926790030884864.0000 - accuracy: 0.3649\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 7331823243755520.0000 - accuracy: 0.3688\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 6854070409101312.0000 - accuracy: 0.3686\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 6471210581884928.0000 - accuracy: 0.3709\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 5932560479682560.0000 - accuracy: 0.3732\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 5996790104981504.0000 - accuracy: 0.3703\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2f458350>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG8zJoA59VLa",
        "outputId": "13330a84-f2b4-41b1-995c-907fcb217bc7"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.30965593457221985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jvvgPr_9VNj"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnUQe85l4A03",
        "outputId": "490be91e-c092-4ece-ba0d-c1e23a2285ca"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.12      0.05        69\n",
            "           1       0.06      0.12      0.08       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.33      0.14      0.20      1191\n",
            "           4       0.35      0.32      0.34      1904\n",
            "           5       0.53      0.36      0.43      2283\n",
            "           9       0.24      0.58      0.34       412\n",
            "          10       0.24      0.52      0.33       573\n",
            "          11       0.13      0.09      0.11       340\n",
            "\n",
            "    accuracy                           0.31      7208\n",
            "   macro avg       0.21      0.25      0.21      7208\n",
            "weighted avg       0.36      0.31      0.31      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUJgNy_h9ulh"
      },
      "source": [
        "# 3 Layer RELU Model with SGD Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiRh6iR89VSk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svwol4pQ9zDh"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE5UoRaH95jR",
        "outputId": "36c1f623-e071-481e-a701-4beafdc48c33"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "77/77 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0520\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 10/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 11/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 12/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 13/20\n",
            "77/77 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 14/20\n",
            "77/77 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 15/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 16/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 17/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 18/20\n",
            "77/77 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 19/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n",
            "Epoch 20/20\n",
            "77/77 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0521\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe86b54e610>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOjLLPx099cJ",
        "outputId": "f2793cae-e99f-4e0c-d7ab-4438962370c1"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.01359600480645895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz8WlqH09_2g"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2JkuNDD4GRW",
        "outputId": "b7759576-c3e1-4e8e-c885-2c6841600d8a"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.02      0.30      0.04        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.01      0.66      0.02       117\n",
            "           3       0.00      0.00      0.00      1191\n",
            "           4       0.00      0.00      0.00      1904\n",
            "           5       0.00      0.00      0.00      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.01      7208\n",
            "   macro avg       0.00      0.11      0.01      7208\n",
            "weighted avg       0.00      0.01      0.00      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ3F-Ysf-F6b"
      },
      "source": [
        "# 3 Layer TANH Model with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yjnFwN9-FQJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynK-BDPG-Q3g"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5SCifEj-S5v",
        "outputId": "14658d67-caeb-4260-99de-8344570ad62a"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.9324 - accuracy: 0.3638\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.4952 - accuracy: 0.4345\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.4110 - accuracy: 0.4624\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.3626 - accuracy: 0.4797\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.3261 - accuracy: 0.4903\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.2958 - accuracy: 0.5065\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.2734 - accuracy: 0.5140\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.2501 - accuracy: 0.5207\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.2343 - accuracy: 0.5273\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.2204 - accuracy: 0.5305\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.2054 - accuracy: 0.5374\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1961 - accuracy: 0.5409\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1862 - accuracy: 0.5434\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.1758 - accuracy: 0.5485\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1662 - accuracy: 0.5520\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1552 - accuracy: 0.5558\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1483 - accuracy: 0.5603\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1422 - accuracy: 0.5611\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1339 - accuracy: 0.5654\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.1289 - accuracy: 0.5651\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2f1abfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvrRmaL--VOo",
        "outputId": "4f75184c-6f15-4b0c-e724-f8692734dcdd"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5602108836174011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1BNYJQT-X24"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD8J5aOI4pWf",
        "outputId": "de2862d6-72ba-4f29-c351-5f79414ac3ac"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg , y_pred_arg))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.89      0.23      0.36       319\n",
            "           2       0.55      0.15      0.24       117\n",
            "           3       0.51      0.68      0.58      1191\n",
            "           4       0.59      0.49      0.54      1904\n",
            "           5       0.54      0.73      0.62      2283\n",
            "           9       0.55      0.38      0.45       412\n",
            "          10       0.70      0.49      0.58       573\n",
            "          11       0.62      0.28      0.38       340\n",
            "\n",
            "    accuracy                           0.56      7208\n",
            "   macro avg       0.55      0.38      0.42      7208\n",
            "weighted avg       0.58      0.56      0.54      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXtWVpA5-c6w"
      },
      "source": [
        "# 3 Layer TANH Model with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4BMILD-akj"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LahZxKmm-pyJ"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyKfA6Ss-tYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2139d4b-78dc-49e3-b1e4-4c0f722cc719"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 2.1781 - accuracy: 0.3028\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.8482 - accuracy: 0.3851\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6872 - accuracy: 0.4030\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6083 - accuracy: 0.4154\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.5651 - accuracy: 0.4233\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.5351 - accuracy: 0.4309\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.5112 - accuracy: 0.4371\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4916 - accuracy: 0.4468\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4748 - accuracy: 0.4502\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4599 - accuracy: 0.4550\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4463 - accuracy: 0.4591\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4339 - accuracy: 0.4617\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4227 - accuracy: 0.4677\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4120 - accuracy: 0.4701\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.4017 - accuracy: 0.4748\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.3927 - accuracy: 0.4758\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.4831\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.3752 - accuracy: 0.4837\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.3671 - accuracy: 0.4897\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.3595 - accuracy: 0.4925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2f0087d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1SUZGBN-vCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e1ae0e-03c7-4d7c-d9c6-488106cd7a58"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.4977802336215973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du55d1Rf-y9q"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97NxMK4m-3C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e59328a-aeb1-4de7-eee0-d58dd372a278"
      },
      "source": [
        "res = tf.math.confusion_matrix(y_test_arg, y_pred_arg)\n",
        "print(res)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   0    0    0   16   26   27    0    0    0    0    0    0]\n",
            " [   0   76    0   36   56  147    0    0    0    0    4    0]\n",
            " [   0    0    0   64   35   18    0    0    0    0    0    0]\n",
            " [   0    0    0  836  150  198    0    0    0    0    7    0]\n",
            " [   0    0    0  320  782  761    0    0    0    0   33    8]\n",
            " [   0    8    0  263  345 1634    0    0    0    0   33    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0   19  191  174    0    0    0   16   12    0]\n",
            " [   0    0    0   19   93  217    0    0    0    0  244    0]\n",
            " [   0    0    0   62  100  178    0    0    0    0    0    0]], shape=(12, 12), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3GgSzf9S2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72dae376-e185-4aee-eda8-a189005f284c"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.90      0.24      0.38       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.51      0.70      0.59      1191\n",
            "           4       0.44      0.41      0.42      1904\n",
            "           5       0.49      0.72      0.58      2283\n",
            "           9       1.00      0.04      0.07       412\n",
            "          10       0.73      0.43      0.54       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.50      7208\n",
            "   macro avg       0.45      0.28      0.29      7208\n",
            "weighted avg       0.51      0.50      0.46      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeOp21qS-7Uz"
      },
      "source": [
        "# 3 Layer Sigmoid with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PybGPLk-8Yh"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qCt6K8I-_qr"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BVCCa74_BZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f426ffbf-74ef-458b-84d4-78ec0e67fddf"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.7320 - accuracy: 0.3393\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.5949 - accuracy: 0.3818\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.5504 - accuracy: 0.4031\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.5136 - accuracy: 0.4159\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.4844 - accuracy: 0.4264\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.4623 - accuracy: 0.4371\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.4409 - accuracy: 0.4493\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.4242 - accuracy: 0.4548\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.4096 - accuracy: 0.4606\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3928 - accuracy: 0.4696\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3782 - accuracy: 0.4742\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3654 - accuracy: 0.4832\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3521 - accuracy: 0.4863\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3419 - accuracy: 0.4909\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3294 - accuracy: 0.4984\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.3196 - accuracy: 0.5025\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.3088 - accuracy: 0.5069\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.2995 - accuracy: 0.5105\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 3ms/step - loss: 1.2906 - accuracy: 0.5148\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.2815 - accuracy: 0.5180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2ee98f50>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x93Yg33y_EZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd812f9c-4eae-44ab-e242-6b0f44a4a2c4"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5095726847648621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrNmOqua_HAz"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBIemFtG9USZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f6766c-083b-416b-d3f4-6b88959f4546"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.71      0.29      0.41       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.51      0.71      0.59      1191\n",
            "           4       0.46      0.43      0.45      1904\n",
            "           5       0.51      0.71      0.60      2283\n",
            "           9       0.49      0.17      0.25       412\n",
            "          10       0.83      0.29      0.43       573\n",
            "          11       0.47      0.14      0.21       340\n",
            "\n",
            "    accuracy                           0.51      7208\n",
            "   macro avg       0.44      0.30      0.33      7208\n",
            "weighted avg       0.52      0.51      0.48      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIKH6JMi_NZ7"
      },
      "source": [
        "# 3 Layer Sigmoid with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG4J0Qul_O4J"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6eNYe7W_Q8K"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T653Orjs_RDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2b899e-4e37-4dd4-dc0e-f6403ca64325"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.9146 - accuracy: 0.2951\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.7372 - accuracy: 0.3304\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.7005 - accuracy: 0.3518\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.6793 - accuracy: 0.3536\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6657 - accuracy: 0.3537\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6559 - accuracy: 0.3541\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6486 - accuracy: 0.3578\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6428 - accuracy: 0.3603\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6379 - accuracy: 0.3627\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6339 - accuracy: 0.3643\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6300 - accuracy: 0.3644\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6266 - accuracy: 0.3686\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6235 - accuracy: 0.3706\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6206 - accuracy: 0.3721\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6178 - accuracy: 0.3745\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6154 - accuracy: 0.3747\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 2ms/step - loss: 1.6128 - accuracy: 0.3775\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6104 - accuracy: 0.3798\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6079 - accuracy: 0.3808\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 0s 2ms/step - loss: 1.6058 - accuracy: 0.3833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2ed0f150>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycBVcqp_RGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e95535c-61cc-4c3c-d191-48416980cf84"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.3920643627643585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR1qieEt_RJP"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9Dky7Z9U9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eec4e27-13a3-4b5a-dd86-8c44adc49e98"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.39      0.76      0.52      1191\n",
            "           4       0.44      0.10      0.16      1904\n",
            "           5       0.39      0.76      0.51      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.39      7208\n",
            "   macro avg       0.14      0.18      0.13      7208\n",
            "weighted avg       0.30      0.39      0.29      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SryIyIgnmF_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgAnvLV_nfuv"
      },
      "source": [
        "# 64 Batch Size, 100 Epocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0M7YFRRnidH"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12UDqTc1_f8j"
      },
      "source": [
        "# 3 Layer RELU with ADAM Optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVQP5QSB_fbp"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZbYXM0gAN3F"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leon-mqNAN5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0274c3f8-d2d7-40d9-94c5-c1002846852d"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 2ms/step - loss: 58712190051418112.0000 - accuracy: 0.3090\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 24121743220146176.0000 - accuracy: 0.3343\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 21452659416367104.0000 - accuracy: 0.3399\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 17305276860334080.0000 - accuracy: 0.3462\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 15072625084596224.0000 - accuracy: 0.3509\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 13666652507865088.0000 - accuracy: 0.3530\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 12495684435443712.0000 - accuracy: 0.3567\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 10145996948373504.0000 - accuracy: 0.3587\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 9227956278788096.0000 - accuracy: 0.3594\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 8509060357816320.0000 - accuracy: 0.3532\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 6434062336000000.0000 - accuracy: 0.3614\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 4958781872013312.0000 - accuracy: 0.3571\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 3750787154968576.0000 - accuracy: 0.3426\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 2033469848813568.0000 - accuracy: 0.3106\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1100263716814848.0000 - accuracy: 0.3496\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 620414132813824.0000 - accuracy: 0.3527\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 392233626894336.0000 - accuracy: 0.3707\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 452678446481408.0000 - accuracy: 0.3661\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 357851776155648.0000 - accuracy: 0.3711\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 294054969475072.0000 - accuracy: 0.3718\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 311681548812288.0000 - accuracy: 0.3675\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 267025112891392.0000 - accuracy: 0.3695\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 163602099077120.0000 - accuracy: 0.3720\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 91691537137664.0000 - accuracy: 0.3455\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 39760169009152.0000 - accuracy: 0.3304\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1768040169472.0000 - accuracy: 0.3270\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 38724911104.0000 - accuracy: 0.3256\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 4450595840.0000 - accuracy: 0.3269\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 32011912.0000 - accuracy: 0.3291\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 2004257.3750 - accuracy: 0.3293\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 8430800.0000 - accuracy: 0.3293\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 11182290.0000 - accuracy: 0.3293\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 4079805.5000 - accuracy: 0.3293\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7300 - accuracy: 0.3291\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7299 - accuracy: 0.3291\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7298 - accuracy: 0.3291\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7297 - accuracy: 0.3291\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 1.7296 - accuracy: 0.3291\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7295 - accuracy: 0.3291\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7295 - accuracy: 0.3291\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7294 - accuracy: 0.3291\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7294 - accuracy: 0.3291\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7294 - accuracy: 0.3291\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.3291\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7293 - accuracy: 0.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2eb8e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWrgg1Z_AN73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44a5a45-a513-46f4-fc3d-0dc8151975cc"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.32741397619247437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57yD_vMjAN-I"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3zRGMB9Vfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdaa6b92-033f-444c-deb5-22ec9f3e44e5"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       1.00      0.17      0.29       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.00      0.00      0.00      1191\n",
            "           4       1.00      0.00      0.00      1904\n",
            "           5       0.32      1.00      0.49      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       1.00      0.03      0.07       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.33      7208\n",
            "   macro avg       0.37      0.13      0.09      7208\n",
            "weighted avg       0.49      0.33      0.17      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfjt-sZDnVkl"
      },
      "source": [
        "# 3 Layer RELU Model with SGD Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvCz0D48nVkt"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQBCQQbknVkt"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqqKIyvKnVkt",
        "outputId": "babcfe92-1aab-4add-ee2e-3fc52dff5be8"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0097\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce23a3ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LhLpnZhnVku",
        "outputId": "2fae4987-36ea-4e3f-deee-2cdb87c504cf"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.00957269687205553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75EdgYDLnVku"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP4wd3znnVku",
        "outputId": "21bb06a1-1eae-46eb-a66b-7fbbce3f866e"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      1.00      0.02        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.00      0.00      0.00      1191\n",
            "           4       0.00      0.00      0.00      1904\n",
            "           5       0.00      0.00      0.00      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.01      7208\n",
            "   macro avg       0.00      0.11      0.00      7208\n",
            "weighted avg       0.00      0.01      0.00      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW9SmZtaoCmR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEwBQj_5oCv_"
      },
      "source": [
        "# 3 Layer TANH Model with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwt-Mh4ToCv_"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB3ch_PqoCv_"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CuzSe2HoCv_",
        "outputId": "ba82e3bf-8ba1-4793-fbfd-5869803ecce1"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.7792 - accuracy: 0.3868\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4400 - accuracy: 0.4472\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3713 - accuracy: 0.4703\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3260 - accuracy: 0.4915\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2952 - accuracy: 0.5016\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2708 - accuracy: 0.5115\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2489 - accuracy: 0.5200\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2316 - accuracy: 0.5235\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2140 - accuracy: 0.5293\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1997 - accuracy: 0.5349\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1883 - accuracy: 0.5383\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1787 - accuracy: 0.5418\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1668 - accuracy: 0.5442\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1562 - accuracy: 0.5514\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1481 - accuracy: 0.5538\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1421 - accuracy: 0.5562\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1351 - accuracy: 0.5576\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1297 - accuracy: 0.5591\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1208 - accuracy: 0.5612\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1169 - accuracy: 0.5642\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1115 - accuracy: 0.5646\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1077 - accuracy: 0.5648\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1040 - accuracy: 0.5676\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0971 - accuracy: 0.5701\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0922 - accuracy: 0.5706\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0885 - accuracy: 0.5739\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0901 - accuracy: 0.5693\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0874 - accuracy: 0.5713\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0801 - accuracy: 0.5742\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0794 - accuracy: 0.5744\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0772 - accuracy: 0.5712\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0714 - accuracy: 0.5758\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0714 - accuracy: 0.5742\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0697 - accuracy: 0.5722\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0685 - accuracy: 0.5754\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0648 - accuracy: 0.5799\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0641 - accuracy: 0.5745\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0624 - accuracy: 0.5763\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0612 - accuracy: 0.5742\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0580 - accuracy: 0.5792\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0581 - accuracy: 0.5792\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0540 - accuracy: 0.5804\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0528 - accuracy: 0.5780\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0501 - accuracy: 0.5787\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0501 - accuracy: 0.5787\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0475 - accuracy: 0.5820\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0476 - accuracy: 0.5802\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0444 - accuracy: 0.5796\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0472 - accuracy: 0.5790\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0455 - accuracy: 0.5791\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0448 - accuracy: 0.5822\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0435 - accuracy: 0.5822\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0415 - accuracy: 0.5810\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0392 - accuracy: 0.5827\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0402 - accuracy: 0.5799\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0395 - accuracy: 0.5810\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0383 - accuracy: 0.5808\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0360 - accuracy: 0.5824\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0371 - accuracy: 0.5827\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0342 - accuracy: 0.5848\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0352 - accuracy: 0.5817\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0336 - accuracy: 0.5848\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0326 - accuracy: 0.5850\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0340 - accuracy: 0.5827\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0310 - accuracy: 0.5833\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0312 - accuracy: 0.5820\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0286 - accuracy: 0.5854\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0288 - accuracy: 0.5849\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0266 - accuracy: 0.5846\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0280 - accuracy: 0.5828\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0276 - accuracy: 0.5848\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0289 - accuracy: 0.5850\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0248 - accuracy: 0.5844\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0291 - accuracy: 0.5825\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0235 - accuracy: 0.5849\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0254 - accuracy: 0.5843\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0232 - accuracy: 0.5856\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0230 - accuracy: 0.5858\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0215 - accuracy: 0.5857\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0215 - accuracy: 0.5847\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0221 - accuracy: 0.5852\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0202 - accuracy: 0.5858\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0220 - accuracy: 0.5871\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0203 - accuracy: 0.5840\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0197 - accuracy: 0.5860\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0190 - accuracy: 0.5879\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0192 - accuracy: 0.5847\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0194 - accuracy: 0.5863\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0191 - accuracy: 0.5863\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0174 - accuracy: 0.5871\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0169 - accuracy: 0.5875\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0177 - accuracy: 0.5876\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0159 - accuracy: 0.5879\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0162 - accuracy: 0.5850\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0170 - accuracy: 0.5861\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0163 - accuracy: 0.5850\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0166 - accuracy: 0.5871\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0154 - accuracy: 0.5857\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0141 - accuracy: 0.5858\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0139 - accuracy: 0.5857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce238cb490>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3HTw5OnoCwA",
        "outputId": "e7945e17-b743-4dbf-a180-857b9b2a54ec"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5918424129486084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OChsnv-JoCwA"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRrBjntRoCwA",
        "outputId": "cf95c933-92a9-412e-a8c9-d2b70ec2cb53"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg , y_pred_arg))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.06      0.11        69\n",
            "           1       0.80      0.36      0.50       319\n",
            "           2       0.88      0.12      0.21       117\n",
            "           3       0.55      0.72      0.63      1191\n",
            "           4       0.55      0.59      0.57      1904\n",
            "           5       0.60      0.70      0.65      2283\n",
            "           9       0.69      0.33      0.45       412\n",
            "          10       0.70      0.57      0.63       573\n",
            "          11       0.75      0.25      0.38       340\n",
            "\n",
            "    accuracy                           0.59      7208\n",
            "   macro avg       0.70      0.41      0.46      7208\n",
            "weighted avg       0.61      0.59      0.58      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmU2ltfcoCwA"
      },
      "source": [
        "# 3 Layer TANH Model with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTewdGg2oCwB"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfFBXUeOoCwB"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wby7ry1oCwB",
        "outputId": "1088be54-62a6-4cb0-82f4-dd433f7cd3de"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 2.0053 - accuracy: 0.3411\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6535 - accuracy: 0.4126\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.5654 - accuracy: 0.4270\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5226 - accuracy: 0.4406\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.4933 - accuracy: 0.4469\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4700 - accuracy: 0.4552\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.4512 - accuracy: 0.4592\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.4335 - accuracy: 0.4659\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.4187 - accuracy: 0.4720\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4048 - accuracy: 0.4814\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3917 - accuracy: 0.4842\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3797 - accuracy: 0.4859\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3681 - accuracy: 0.4932\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3580 - accuracy: 0.4952\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3473 - accuracy: 0.5030\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3382 - accuracy: 0.5032\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3291 - accuracy: 0.5059\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3208 - accuracy: 0.5098\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.3119 - accuracy: 0.5118\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3040 - accuracy: 0.5163\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2961 - accuracy: 0.5172\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2893 - accuracy: 0.5217\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2826 - accuracy: 0.5237\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2757 - accuracy: 0.5234\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2691 - accuracy: 0.5269\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2630 - accuracy: 0.5288\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2565 - accuracy: 0.5295\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2515 - accuracy: 0.5349\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2461 - accuracy: 0.5349\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.2398 - accuracy: 0.5380\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.2348 - accuracy: 0.5405\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2292 - accuracy: 0.5426\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2243 - accuracy: 0.5464\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2192 - accuracy: 0.5441\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2152 - accuracy: 0.5452\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2095 - accuracy: 0.5487\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2056 - accuracy: 0.5503\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2007 - accuracy: 0.5508\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1968 - accuracy: 0.5521\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1925 - accuracy: 0.5533\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1886 - accuracy: 0.5566\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1845 - accuracy: 0.5561\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1797 - accuracy: 0.5602\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1767 - accuracy: 0.5595\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1726 - accuracy: 0.5613\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1692 - accuracy: 0.5618\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1659 - accuracy: 0.5609\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1622 - accuracy: 0.5629\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1589 - accuracy: 0.5628\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1553 - accuracy: 0.5638\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1514 - accuracy: 0.5659\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1488 - accuracy: 0.5665\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1452 - accuracy: 0.5662\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1421 - accuracy: 0.5666\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1405 - accuracy: 0.5680\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1366 - accuracy: 0.5689\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1342 - accuracy: 0.5693\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1312 - accuracy: 0.5711\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1278 - accuracy: 0.5707\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1270 - accuracy: 0.5703\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1236 - accuracy: 0.5718\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1202 - accuracy: 0.5719\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1184 - accuracy: 0.5729\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1166 - accuracy: 0.5738\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1135 - accuracy: 0.5748\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1111 - accuracy: 0.5745\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1090 - accuracy: 0.5755\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1078 - accuracy: 0.5741\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1043 - accuracy: 0.5763\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1015 - accuracy: 0.5773\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.1005 - accuracy: 0.5788\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.0986 - accuracy: 0.5783\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.0957 - accuracy: 0.5810\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.0946 - accuracy: 0.5787\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0915 - accuracy: 0.5797\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0914 - accuracy: 0.5785\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0894 - accuracy: 0.5812\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0875 - accuracy: 0.5825\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0850 - accuracy: 0.5821\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0831 - accuracy: 0.5823\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0817 - accuracy: 0.5843\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0805 - accuracy: 0.5817\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0779 - accuracy: 0.5826\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0776 - accuracy: 0.5835\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0765 - accuracy: 0.5807\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0740 - accuracy: 0.5838\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0729 - accuracy: 0.5846\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0716 - accuracy: 0.5848\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0692 - accuracy: 0.5858\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0679 - accuracy: 0.5832\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0670 - accuracy: 0.5850\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.0645 - accuracy: 0.5860\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0643 - accuracy: 0.5832\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0614 - accuracy: 0.5870\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0617 - accuracy: 0.5868\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0600 - accuracy: 0.5862\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0594 - accuracy: 0.5856\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0571 - accuracy: 0.5876\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0558 - accuracy: 0.5862\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0539 - accuracy: 0.5865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce237ea050>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOHyVmPUoCwB",
        "outputId": "320b92e3-1011-4295-8837-bdb9983ad093"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5761653780937195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaVK0Pq3oCwB"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AKfmLD8oCwC",
        "outputId": "40d91719-acdd-4606-b631-175fdb7d23f3"
      },
      "source": [
        "res = tf.math.confusion_matrix(y_test_arg, y_pred_arg)\n",
        "print(res)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   0    0    2   35   12   18    0    0    0    0    0    2]\n",
            " [   0  107    1   44   44  111    0    0    0    4    0    8]\n",
            " [   0    1   21   79   10    5    0    0    0    0    0    1]\n",
            " [   0    2   13  964   83  103    0    0    0    3   12   11]\n",
            " [   0    1    1  414  923  463    0    0    0   55   24   23]\n",
            " [   0   21    3  348  179 1641    0    0    0   47   33   11]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    1    2   24   85  110    0    0    0  151    6   33]\n",
            " [   0    0    0   30   91  166    0    0    0   21  265    0]\n",
            " [   0    0    0   89   39  108    0    0    0   17    6   81]], shape=(12, 12), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJiLcn5aoCwC",
        "outputId": "677dc871-cb6d-475e-de29-f9969c770779"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.80      0.34      0.47       319\n",
            "           2       0.49      0.18      0.26       117\n",
            "           3       0.48      0.81      0.60      1191\n",
            "           4       0.63      0.48      0.55      1904\n",
            "           5       0.60      0.72      0.66      2283\n",
            "           9       0.51      0.37      0.43       412\n",
            "          10       0.77      0.46      0.58       573\n",
            "          11       0.48      0.24      0.32       340\n",
            "\n",
            "    accuracy                           0.58      7208\n",
            "   macro avg       0.53      0.40      0.43      7208\n",
            "weighted avg       0.59      0.58      0.56      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTMquuFKoCwC"
      },
      "source": [
        "# 3 Layer Sigmoid with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAcyiVkzoCwC"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBtE-6TwoCwD"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzPD-hZsoCwD",
        "outputId": "534d21f8-e0e4-47b5-87f8-fc89b5350c27"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6657 - accuracy: 0.3621\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5543 - accuracy: 0.3926\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5036 - accuracy: 0.4141\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4694 - accuracy: 0.4307\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4441 - accuracy: 0.4395\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4246 - accuracy: 0.4540\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4072 - accuracy: 0.4621\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3906 - accuracy: 0.4662\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3744 - accuracy: 0.4756\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3609 - accuracy: 0.4812\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3483 - accuracy: 0.4843\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3358 - accuracy: 0.4920\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3243 - accuracy: 0.4928\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3142 - accuracy: 0.4968\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.3042 - accuracy: 0.5019\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2955 - accuracy: 0.5042\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2849 - accuracy: 0.5063\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2763 - accuracy: 0.5084\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2694 - accuracy: 0.5124\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2605 - accuracy: 0.5131\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2537 - accuracy: 0.5173\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2472 - accuracy: 0.5194\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2409 - accuracy: 0.5224\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2353 - accuracy: 0.5249\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2287 - accuracy: 0.5251\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2230 - accuracy: 0.5298\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2187 - accuracy: 0.5295\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2134 - accuracy: 0.5311\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2076 - accuracy: 0.5331\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.2032 - accuracy: 0.5328\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1986 - accuracy: 0.5338\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1940 - accuracy: 0.5371\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1904 - accuracy: 0.5370\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1847 - accuracy: 0.5394\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1806 - accuracy: 0.5391\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1780 - accuracy: 0.5411\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1760 - accuracy: 0.5413\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1700 - accuracy: 0.5429\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1672 - accuracy: 0.5434\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1620 - accuracy: 0.5444\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1589 - accuracy: 0.5476\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1580 - accuracy: 0.5463\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1556 - accuracy: 0.5458\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1520 - accuracy: 0.5515\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1460 - accuracy: 0.5516\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1443 - accuracy: 0.5518\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1434 - accuracy: 0.5518\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1377 - accuracy: 0.5565\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1379 - accuracy: 0.5537\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1335 - accuracy: 0.5547\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1311 - accuracy: 0.5570\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1297 - accuracy: 0.5567\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1260 - accuracy: 0.5586\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1240 - accuracy: 0.5601\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1238 - accuracy: 0.5577\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1198 - accuracy: 0.5586\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1184 - accuracy: 0.5592\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1177 - accuracy: 0.5601\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1140 - accuracy: 0.5644\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1123 - accuracy: 0.5624\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1099 - accuracy: 0.5645\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1093 - accuracy: 0.5616\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1071 - accuracy: 0.5644\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1047 - accuracy: 0.5653\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1015 - accuracy: 0.5663\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.1024 - accuracy: 0.5629\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0988 - accuracy: 0.5677\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0977 - accuracy: 0.5667\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0970 - accuracy: 0.5659\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0948 - accuracy: 0.5649\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0937 - accuracy: 0.5675\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0911 - accuracy: 0.5693\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0900 - accuracy: 0.5673\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0887 - accuracy: 0.5682\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0867 - accuracy: 0.5699\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0851 - accuracy: 0.5692\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0846 - accuracy: 0.5693\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0827 - accuracy: 0.5710\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0812 - accuracy: 0.5695\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0786 - accuracy: 0.5717\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0799 - accuracy: 0.5715\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0757 - accuracy: 0.5721\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0766 - accuracy: 0.5727\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0762 - accuracy: 0.5722\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0733 - accuracy: 0.5722\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0701 - accuracy: 0.5718\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0704 - accuracy: 0.5720\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0694 - accuracy: 0.5725\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0689 - accuracy: 0.5752\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0662 - accuracy: 0.5746\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0636 - accuracy: 0.5749\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0664 - accuracy: 0.5753\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0634 - accuracy: 0.5754\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0635 - accuracy: 0.5749\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0614 - accuracy: 0.5737\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0617 - accuracy: 0.5744\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0590 - accuracy: 0.5772\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0578 - accuracy: 0.5764\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0601 - accuracy: 0.5732\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.0579 - accuracy: 0.5762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce235c6c90>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7hvD_3yoCwD",
        "outputId": "93a2e09b-bf48-404c-b7a2-347c3bb9fd4c"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5750554800033569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hx_OdNloCwD"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSBLWwlvoCwE",
        "outputId": "145d4c43-df1f-4578-905b-d4ede4bcdc7b"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.14      0.22        69\n",
            "           1       0.60      0.29      0.39       319\n",
            "           2       0.41      0.32      0.36       117\n",
            "           3       0.59      0.67      0.63      1191\n",
            "           4       0.52      0.59      0.56      1904\n",
            "           5       0.64      0.60      0.62      2283\n",
            "           9       0.54      0.46      0.50       412\n",
            "          10       0.55      0.66      0.60       573\n",
            "          11       0.52      0.38      0.44       340\n",
            "\n",
            "    accuracy                           0.58      7208\n",
            "   macro avg       0.53      0.46      0.48      7208\n",
            "weighted avg       0.58      0.58      0.57      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoxShjvjoCwE"
      },
      "source": [
        "# 3 Layer Sigmoid with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDvouOWkoCwE"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAu-aWkhoCwE"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa8DwprvoCwE",
        "outputId": "730657c9-8c3d-4bd9-c8aa-f3e626d183a6"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.8248 - accuracy: 0.3015\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6948 - accuracy: 0.3469\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6688 - accuracy: 0.3595\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6551 - accuracy: 0.3661\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6454 - accuracy: 0.3681\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.3682\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6314 - accuracy: 0.3713\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6260 - accuracy: 0.3730\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6209 - accuracy: 0.3765\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6162 - accuracy: 0.3759\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6118 - accuracy: 0.3787\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6073 - accuracy: 0.3797\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.6034 - accuracy: 0.3811\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5991 - accuracy: 0.3816\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5951 - accuracy: 0.3824\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5911 - accuracy: 0.3835\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5871 - accuracy: 0.3837\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5832 - accuracy: 0.3842\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5793 - accuracy: 0.3835\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5753 - accuracy: 0.3876\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5716 - accuracy: 0.3881\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5677 - accuracy: 0.3912\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5641 - accuracy: 0.3912\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5603 - accuracy: 0.3947\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5566 - accuracy: 0.3953\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5531 - accuracy: 0.3980\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5497 - accuracy: 0.4001\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5462 - accuracy: 0.4017\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5427 - accuracy: 0.4053\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5395 - accuracy: 0.4078\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5362 - accuracy: 0.4092\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 1s 1ms/step - loss: 1.5329 - accuracy: 0.4098\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5296 - accuracy: 0.4099\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5268 - accuracy: 0.4115\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5240 - accuracy: 0.4130\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5208 - accuracy: 0.4152\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5181 - accuracy: 0.4153\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5152 - accuracy: 0.4183\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5127 - accuracy: 0.4214\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5099 - accuracy: 0.4236\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5073 - accuracy: 0.4274\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5047 - accuracy: 0.4255\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.5023 - accuracy: 0.4296\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4999 - accuracy: 0.4327\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4975 - accuracy: 0.4346\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4951 - accuracy: 0.4352\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4930 - accuracy: 0.4358\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4905 - accuracy: 0.4372\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4885 - accuracy: 0.4388\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4865 - accuracy: 0.4396\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4842 - accuracy: 0.4392\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4823 - accuracy: 0.4400\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4803 - accuracy: 0.4413\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4783 - accuracy: 0.4422\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4762 - accuracy: 0.4422\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4743 - accuracy: 0.4438\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4725 - accuracy: 0.4425\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4705 - accuracy: 0.4455\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4686 - accuracy: 0.4452\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4669 - accuracy: 0.4445\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4652 - accuracy: 0.4456\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4636 - accuracy: 0.4448\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4615 - accuracy: 0.4465\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4600 - accuracy: 0.4466\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4580 - accuracy: 0.4451\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4565 - accuracy: 0.4474\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4548 - accuracy: 0.4478\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4531 - accuracy: 0.4459\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4513 - accuracy: 0.4471\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4500 - accuracy: 0.4474\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4483 - accuracy: 0.4472\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4468 - accuracy: 0.4488\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4452 - accuracy: 0.4502\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4433 - accuracy: 0.4498\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4422 - accuracy: 0.4512\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4406 - accuracy: 0.4510\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4390 - accuracy: 0.4498\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4376 - accuracy: 0.4503\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4362 - accuracy: 0.4508\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4347 - accuracy: 0.4517\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4334 - accuracy: 0.4512\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4317 - accuracy: 0.4525\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4306 - accuracy: 0.4532\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4291 - accuracy: 0.4532\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4276 - accuracy: 0.4528\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4262 - accuracy: 0.4532\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4247 - accuracy: 0.4541\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4234 - accuracy: 0.4544\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4219 - accuracy: 0.4541\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4204 - accuracy: 0.4550\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.4546\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4178 - accuracy: 0.4578\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4162 - accuracy: 0.4572\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4151 - accuracy: 0.4563\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4135 - accuracy: 0.4576\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4122 - accuracy: 0.4598\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4109 - accuracy: 0.4595\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4094 - accuracy: 0.4600\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4086 - accuracy: 0.4618\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 1.4071 - accuracy: 0.4604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce2f0b2550>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PB-30x4oCwF",
        "outputId": "8046cc58-c7c0-410c-df58-622c54e22dbb"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.46711987257003784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMpZmtxloCwF"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBft0k9EoCwF",
        "outputId": "43f259d8-fffa-4f64-eb50-056176f672b7"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.42      0.13      0.20       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.46      0.72      0.56      1191\n",
            "           4       0.43      0.44      0.43      1904\n",
            "           5       0.50      0.67      0.57      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.49      0.18      0.26       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.47      7208\n",
            "   macro avg       0.25      0.24      0.23      7208\n",
            "weighted avg       0.40      0.47      0.42      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ornKPcOjkkf"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsaOYiTuTGG7"
      },
      "source": [
        "![optimizer.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ouW0UX3jS-I"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oAGggN4jVR-"
      },
      "source": [
        "When creating the Deep Learning model, I used three different activation functions:  RELU, Tanh, and Sigmoid.\n",
        "\n",
        "Each model only consisted of three layers, with two different optimizers applied for each model.  The optimizers are:  ADAM & SGD\n",
        "\n",
        "Once I was able to determine which activation function and which optimizer provided the best results, I had increased the amount of epochs from 20 to 100.  I also decreased the batch size in the second table to see if it made a difference in accuracy.\n",
        "\n",
        "Overall, it made a very small difference.  The most gain a model received was TANH Model with the SGD Optimizer, rising from 0.50 to 0.58 accuracy.  \n",
        "\n",
        "The highest accuracy I was able to get was 0.59 from the TANH Model with ADAM Optimizer with the Batch Size set at 64 with an EPOC level at 100.  \n"
      ]
    }
  ]
}