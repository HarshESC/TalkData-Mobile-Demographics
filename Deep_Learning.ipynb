{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7+VA0RJ/XkMBxgNNTVkY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshESC/TalkData-Mobile-Demographics/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00cXoM1C7SZM",
        "outputId": "11702ef9-150b-4ffa-ae25-a646d4b18554"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import (\n",
        "    Activation,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/\"\n",
        "%cd \"/content/gdrive/My Drive/Final Capstone\"\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Final Capstone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-v5hZv8Ujo"
      },
      "source": [
        "master_df = pd.read_csv(\"master_clean_2.csv\")\n",
        "X = master_df.drop(columns=[\"num_group\"])\n",
        "y = master_df[\"num_group\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=13, stratify=y\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "C8cQacRX8tkQ",
        "outputId": "ffc0fa40-24b1-44af-ceaa-df98e306d60c"
      },
      "source": [
        "X_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>device_id</th>\n",
              "      <th>label_id_x</th>\n",
              "      <th>download_id</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>405</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>704</th>\n",
              "      <th>713</th>\n",
              "      <th>730</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>761</th>\n",
              "      <th>775</th>\n",
              "      <th>777</th>\n",
              "      <th>779</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>787</th>\n",
              "      <th>959</th>\n",
              "      <th>960</th>\n",
              "      <th>1007</th>\n",
              "      <th>english_phone_brand_coolpad</th>\n",
              "      <th>english_phone_brand_huawei</th>\n",
              "      <th>english_phone_brand_lshi</th>\n",
              "      <th>english_phone_brand_meizu</th>\n",
              "      <th>english_phone_brand_oppo</th>\n",
              "      <th>english_phone_brand_samsung</th>\n",
              "      <th>english_phone_brand_xiaomi</th>\n",
              "      <th>device_model_Galaxy Note 3</th>\n",
              "      <th>device_model_MI 4</th>\n",
              "      <th>device_model_MX4</th>\n",
              "      <th>device_model_MX5</th>\n",
              "      <th>device_model_Mate 7</th>\n",
              "      <th>device_model_R7s</th>\n",
              "      <th>device_model_U3</th>\n",
              "      <th>device_model_note顶配版</th>\n",
              "      <th>device_model_小米note</th>\n",
              "      <th>device_model_荣耀6</th>\n",
              "      <th>device_model_荣耀6 Plus</th>\n",
              "      <th>device_model_超级手机1 Pro</th>\n",
              "      <th>device_model_魅蓝metal</th>\n",
              "      <th>device_model_麦芒4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3972</th>\n",
              "      <td>331345</td>\n",
              "      <td>-1633912816187681087</td>\n",
              "      <td>1</td>\n",
              "      <td>-9170266620213363189</td>\n",
              "      <td>787</td>\n",
              "      <td>7642564637308507340</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34708</th>\n",
              "      <td>3137225</td>\n",
              "      <td>4348659952760821294</td>\n",
              "      <td>1</td>\n",
              "      <td>-1665198983206396063</td>\n",
              "      <td>548</td>\n",
              "      <td>2683460969554425231</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>144053</td>\n",
              "      <td>-8103714741965524240</td>\n",
              "      <td>0</td>\n",
              "      <td>2596032420261205364</td>\n",
              "      <td>787</td>\n",
              "      <td>-5507682321704318876</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8021</th>\n",
              "      <td>663472</td>\n",
              "      <td>-1200607960388315089</td>\n",
              "      <td>0</td>\n",
              "      <td>5499466531572133131</td>\n",
              "      <td>713</td>\n",
              "      <td>4298858571183818042</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10225</th>\n",
              "      <td>913759</td>\n",
              "      <td>33792862810792679</td>\n",
              "      <td>0</td>\n",
              "      <td>1734050676638523012</td>\n",
              "      <td>713</td>\n",
              "      <td>1767843539449315691</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34832</th>\n",
              "      <td>3148380</td>\n",
              "      <td>-9050100410106163077</td>\n",
              "      <td>0</td>\n",
              "      <td>-1544445963999571951</td>\n",
              "      <td>787</td>\n",
              "      <td>7852197699603816588</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>45155</td>\n",
              "      <td>7316250158002095415</td>\n",
              "      <td>0</td>\n",
              "      <td>-4483258470894206861</td>\n",
              "      <td>757</td>\n",
              "      <td>2832991687107888554</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14095</th>\n",
              "      <td>1165984</td>\n",
              "      <td>-1073344577746533072</td>\n",
              "      <td>0</td>\n",
              "      <td>5499466531572133131</td>\n",
              "      <td>730</td>\n",
              "      <td>4426121953825600059</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23610</th>\n",
              "      <td>2117736</td>\n",
              "      <td>-974457023668610292</td>\n",
              "      <td>0</td>\n",
              "      <td>-6335083146238767307</td>\n",
              "      <td>761</td>\n",
              "      <td>-7309540169907377599</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12927</th>\n",
              "      <td>1077613</td>\n",
              "      <td>-7509752927626140732</td>\n",
              "      <td>0</td>\n",
              "      <td>5499466531572133131</td>\n",
              "      <td>1007</td>\n",
              "      <td>-2010286396054007601</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7208 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       event_id               app_id  ...  device_model_魅蓝metal  device_model_麦芒4\n",
              "3972     331345 -1633912816187681087  ...                     0                 0\n",
              "34708   3137225  4348659952760821294  ...                     0                 0\n",
              "1279     144053 -8103714741965524240  ...                     0                 0\n",
              "8021     663472 -1200607960388315089  ...                     0                 0\n",
              "10225    913759    33792862810792679  ...                     0                 1\n",
              "...         ...                  ...  ...                   ...               ...\n",
              "34832   3148380 -9050100410106163077  ...                     0                 0\n",
              "471       45155  7316250158002095415  ...                     0                 0\n",
              "14095   1165984 -1073344577746533072  ...                     0                 0\n",
              "23610   2117736  -974457023668610292  ...                     0                 0\n",
              "12927   1077613 -7509752927626140732  ...                     0                 0\n",
              "\n",
              "[7208 rows x 47 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy29E6s58qFw",
        "outputId": "61fc4414-4162-47cc-c8af-5f60a0d0e25a"
      },
      "source": [
        "y_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3972      5\n",
              "34708     5\n",
              "1279     10\n",
              "8021      5\n",
              "10225     5\n",
              "         ..\n",
              "34832     4\n",
              "471       1\n",
              "14095     5\n",
              "23610     3\n",
              "12927     5\n",
              "Name: num_group, Length: 7208, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JmSf11G8tOw",
        "outputId": "ab78c90b-b235-419f-b4cd-00be5d9161e4"
      },
      "source": [
        "master_df[\"num_group\"].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5     11416\n",
              "4      9521\n",
              "3      5955\n",
              "10     2862\n",
              "9      2060\n",
              "11     1697\n",
              "1      1596\n",
              "2       585\n",
              "0       345\n",
              "Name: num_group, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqxmmCTf9FMp"
      },
      "source": [
        "# Output_dim = 12 because there are 12 different age/gender groups\n",
        "output_dim = 12\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNKISkde9JS4"
      },
      "source": [
        "X_train_np = X_train.to_numpy()\n",
        "X_test_np = X_test.to_numpy()\n",
        "y_train = to_categorical(y_train, output_dim)\n",
        "y_test = to_categorical(y_test, output_dim)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1zuYICnvZc"
      },
      "source": [
        "# 128 Batch, 20 Epocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5WNq59h9QcI"
      },
      "source": [
        "# 3 Layer RELU Model with ADAM Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY_ZKoNq9Nnx"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUmZQDJ49VGY"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATVPSjH09VI4",
        "outputId": "bf2b0a82-2845-4510-ab7d-fb84c03b19f6"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 4s 4ms/step - loss: 63236422701678592.0000 - accuracy: 0.3089\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 19599780460101632.0000 - accuracy: 0.3288\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 16811627277975552.0000 - accuracy: 0.3390\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 17722020758290432.0000 - accuracy: 0.3407\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 15613668557324288.0000 - accuracy: 0.3337\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 14648221112467456.0000 - accuracy: 0.3411\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 12939458710077440.0000 - accuracy: 0.3445\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 13130540731334656.0000 - accuracy: 0.3438\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 12989687278862336.0000 - accuracy: 0.3492\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 11537385963651072.0000 - accuracy: 0.3476\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 10765320495038464.0000 - accuracy: 0.3486\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 10134986799710208.0000 - accuracy: 0.3495\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 9802819397746688.0000 - accuracy: 0.3515\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 9876187102838784.0000 - accuracy: 0.3502\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 8467723445075968.0000 - accuracy: 0.3548\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 7825960304902144.0000 - accuracy: 0.3611\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 7911467198185472.0000 - accuracy: 0.3571\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 5ms/step - loss: 7643214278295552.0000 - accuracy: 0.3499\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 7451878317096960.0000 - accuracy: 0.3621\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 6975051047895040.0000 - accuracy: 0.3638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdaa00592d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG8zJoA59VLa",
        "outputId": "f3dd3ef6-ab79-479c-973c-90feabc65ed3"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.3263041079044342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jvvgPr_9VNj"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnUQe85l4A03",
        "outputId": "b83468e7-57c7-484f-d8bd-4ed7c957244a"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.22      0.10      0.13       319\n",
            "           2       0.03      0.17      0.06       117\n",
            "           3       0.38      0.40      0.39      1191\n",
            "           4       0.31      0.47      0.37      1904\n",
            "           5       0.68      0.24      0.36      2283\n",
            "           9       0.27      0.24      0.25       412\n",
            "          10       0.74      0.33      0.46       573\n",
            "          11       0.11      0.28      0.16       340\n",
            "\n",
            "    accuracy                           0.33      7208\n",
            "   macro avg       0.30      0.25      0.24      7208\n",
            "weighted avg       0.45      0.33      0.34      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuM02HG2Gt60"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC8S5Hh6Gx5c",
        "outputId": "312c0670-df02-4288-9201-a6a932546fc3"
      },
      "source": [
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5778483865704016"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUJgNy_h9ulh"
      },
      "source": [
        "# 3 Layer RELU Model with SGD Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiRh6iR89VSk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svwol4pQ9zDh"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE5UoRaH95jR",
        "outputId": "4b8896f7-2cde-4b92-de0d-e972d793b1ce"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0102\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.0096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda336af050>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOjLLPx099cJ",
        "outputId": "6d698d94-6cba-41fb-83b8-64f7bc7de878"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.00957269687205553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz8WlqH09_2g"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2JkuNDD4GRW",
        "outputId": "1be74d28-b8f9-4c38-881e-be99be5bb5f7"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      1.00      0.02        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.00      0.00      0.00      1191\n",
            "           4       0.00      0.00      0.00      1904\n",
            "           5       0.00      0.00      0.00      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.01      7208\n",
            "   macro avg       0.00      0.11      0.00      7208\n",
            "weighted avg       0.00      0.01      0.00      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa2sDZRNAeRE"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lteu1FpGAeUc",
        "outputId": "1989030e-d3c1-4ac5-eab2-3ce64f9d8e36"
      },
      "source": [
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ3F-Ysf-F6b"
      },
      "source": [
        "# 3 Layer TANH Model with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yjnFwN9-FQJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynK-BDPG-Q3g"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5SCifEj-S5v",
        "outputId": "a06d41e6-4b91-4216-cbd5-ae15ca55e35f"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.9556 - accuracy: 0.3629\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4780 - accuracy: 0.4491\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3829 - accuracy: 0.4784\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3326 - accuracy: 0.4946\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.2944 - accuracy: 0.5141\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.2700 - accuracy: 0.5160\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.2436 - accuracy: 0.5321\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.2241 - accuracy: 0.5357\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.2067 - accuracy: 0.5426\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1917 - accuracy: 0.5448\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1819 - accuracy: 0.5472\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1677 - accuracy: 0.5526\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1594 - accuracy: 0.5548\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1487 - accuracy: 0.5578\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1418 - accuracy: 0.5625\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1332 - accuracy: 0.5633\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1245 - accuracy: 0.5662\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1184 - accuracy: 0.5677\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1157 - accuracy: 0.5678\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.1076 - accuracy: 0.5682\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda33522550>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvrRmaL--VOo",
        "outputId": "a10d8cc4-939b-46a8-c384-aef7336a875d"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5704772472381592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1BNYJQT-X24"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD8J5aOI4pWf",
        "outputId": "6077946c-b87b-48a4-8d00-c07c89f2caf1"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg , y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.01      0.03        69\n",
            "           1       0.76      0.35      0.48       319\n",
            "           2       0.56      0.13      0.21       117\n",
            "           3       0.55      0.61      0.58      1191\n",
            "           4       0.50      0.62      0.55      1904\n",
            "           5       0.62      0.67      0.64      2283\n",
            "           9       0.57      0.46      0.51       412\n",
            "          10       0.77      0.46      0.58       573\n",
            "          11       0.53      0.24      0.33       340\n",
            "\n",
            "    accuracy                           0.57      7208\n",
            "   macro avg       0.58      0.40      0.43      7208\n",
            "weighted avg       0.58      0.57      0.56      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxZgYHJbAmYW",
        "outputId": "1a330739-9f44-421f-8f0d-08c61f3631a6"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6665181666486082"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXtWVpA5-c6w"
      },
      "source": [
        "# 3 Layer TANH Model with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4BMILD-akj"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LahZxKmm-pyJ"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyKfA6Ss-tYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15cb6efe-98df-4b97-d8fa-b854a1bb596a"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 2.2475 - accuracy: 0.2641\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.8813 - accuracy: 0.3685\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.7147 - accuracy: 0.4001\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6315 - accuracy: 0.4041\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5861 - accuracy: 0.4119\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5563 - accuracy: 0.4187\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5340 - accuracy: 0.4269\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5151 - accuracy: 0.4361\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4991 - accuracy: 0.4420\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4844 - accuracy: 0.4459\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4717 - accuracy: 0.4501\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4600 - accuracy: 0.4520\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4491 - accuracy: 0.4562\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4389 - accuracy: 0.4607\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4294 - accuracy: 0.4629\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4203 - accuracy: 0.4669\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4117 - accuracy: 0.4705\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4037 - accuracy: 0.4758\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3959 - accuracy: 0.4794\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3884 - accuracy: 0.4818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda33409950>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1SUZGBN-vCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630a8f0d-8f9d-46dd-dea0-e7d2a14ced17"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.48709768056869507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du55d1Rf-y9q"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97NxMK4m-3C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f597f987-61d5-4cad-e654-9db932dc6264"
      },
      "source": [
        "res = tf.math.confusion_matrix(y_test_arg, y_pred_arg)\n",
        "print(res)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   0    0    0   24   15   30    0    0    0    0    0    0]\n",
            " [   0   61    0   51   74  131    0    0    0    0    2    0]\n",
            " [   0    0    0   73   30   14    0    0    0    0    0    0]\n",
            " [   0    0    0  836  145  201    0    0    0    1    8    0]\n",
            " [   0    0    0  289  897  692    0    0    0    6   20    0]\n",
            " [   0   60    0  309  367 1483    0    0    0    0   64    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0   48  179  154    0    0    0   24    7    0]\n",
            " [   0    0    0   24  143  184    0    0    0   12  210    0]\n",
            " [   0    0    0   52  138  144    0    0    0    0    6    0]], shape=(12, 12), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3GgSzf9S2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d41f89-988d-49cf-dbbb-b6bb3f4d2ba0"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.50      0.19      0.28       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.49      0.70      0.58      1191\n",
            "           4       0.45      0.47      0.46      1904\n",
            "           5       0.49      0.65      0.56      2283\n",
            "           9       0.56      0.06      0.11       412\n",
            "          10       0.66      0.37      0.47       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.49      7208\n",
            "   macro avg       0.35      0.27      0.27      7208\n",
            "weighted avg       0.46      0.49      0.45      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iExeKS9AA0hX",
        "outputId": "303c8a2c-753d-466f-dce0-38a491c56455"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.596997709153109"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeOp21qS-7Uz"
      },
      "source": [
        "# 3 Layer Sigmoid with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PybGPLk-8Yh"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qCt6K8I-_qr"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BVCCa74_BZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd67db49-02ba-4105-e46f-a325f94aad90"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6907 - accuracy: 0.3515\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5806 - accuracy: 0.3910\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5368 - accuracy: 0.4034\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.5059 - accuracy: 0.4156\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4816 - accuracy: 0.4268\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4608 - accuracy: 0.4391\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4419 - accuracy: 0.4517\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4270 - accuracy: 0.4516\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.4118 - accuracy: 0.4603\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3999 - accuracy: 0.4629\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3870 - accuracy: 0.4698\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3761 - accuracy: 0.4777\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3662 - accuracy: 0.4781\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3568 - accuracy: 0.4868\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3456 - accuracy: 0.4907\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3380 - accuracy: 0.4928\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3296 - accuracy: 0.4959\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3213 - accuracy: 0.4996\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3139 - accuracy: 0.5023\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.3076 - accuracy: 0.5030\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda331bae10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x93Yg33y_EZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c494560e-2dbc-4d45-de7d-28c3e81bdd95"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5036070942878723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrNmOqua_HAz"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBIemFtG9USZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff62af4-c556-459b-af86-51b4b420f3d7"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.83      0.18      0.30       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.54      0.60      0.57      1191\n",
            "           4       0.40      0.68      0.50      1904\n",
            "           5       0.59      0.57      0.58      2283\n",
            "           9       0.51      0.12      0.19       412\n",
            "          10       0.72      0.39      0.51       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.50      7208\n",
            "   macro avg       0.40      0.28      0.29      7208\n",
            "weighted avg       0.51      0.50      0.48      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVNjZyONBJ80",
        "outputId": "03edbe90-4535-4bbd-e0c1-2b4a3282ca02"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6037469197058289"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIKH6JMi_NZ7"
      },
      "source": [
        "# 3 Layer Sigmoid with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG4J0Qul_O4J"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6eNYe7W_Q8K"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T653Orjs_RDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b5986f-e5e7-4b25-9c9e-afbc1106f062"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.8847 - accuracy: 0.2963\n",
            "Epoch 2/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.7423 - accuracy: 0.3281\n",
            "Epoch 3/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.7062 - accuracy: 0.3396\n",
            "Epoch 4/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6863 - accuracy: 0.3440\n",
            "Epoch 5/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6732 - accuracy: 0.3505\n",
            "Epoch 6/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6636 - accuracy: 0.3567\n",
            "Epoch 7/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6560 - accuracy: 0.3587\n",
            "Epoch 8/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6501 - accuracy: 0.3588\n",
            "Epoch 9/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6447 - accuracy: 0.3593\n",
            "Epoch 10/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6401 - accuracy: 0.3615\n",
            "Epoch 11/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6360 - accuracy: 0.3649\n",
            "Epoch 12/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6322 - accuracy: 0.3675\n",
            "Epoch 13/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6288 - accuracy: 0.3692\n",
            "Epoch 14/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6254 - accuracy: 0.3697\n",
            "Epoch 15/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6223 - accuracy: 0.3722\n",
            "Epoch 16/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6193 - accuracy: 0.3737\n",
            "Epoch 17/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6163 - accuracy: 0.3755\n",
            "Epoch 18/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6137 - accuracy: 0.3759\n",
            "Epoch 19/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6110 - accuracy: 0.3769\n",
            "Epoch 20/20\n",
            "226/226 [==============================] - 1s 4ms/step - loss: 1.6084 - accuracy: 0.3775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda33023390>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycBVcqp_RGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155a8bfe-f69b-4b4a-ee82-52c080aabbe1"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.38249167799949646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR1qieEt_RJP"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9Dky7Z9U9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3373126f-1fa0-4951-93c0-b45b5a9e3b95"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.40      0.76      0.53      1191\n",
            "           4       0.38      0.18      0.24      1904\n",
            "           5       0.37      0.66      0.48      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.38      7208\n",
            "   macro avg       0.13      0.18      0.14      7208\n",
            "weighted avg       0.28      0.38      0.30      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZTY86DjBM7E",
        "outputId": "7eae74b0-6f50-4c3d-a234-451ba539922a"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5420501416170193"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgAnvLV_nfuv"
      },
      "source": [
        "# 64 Batch Size, 100 Epocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0M7YFRRnidH"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12UDqTc1_f8j"
      },
      "source": [
        "# 3 Layer RELU with ADAM Optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVQP5QSB_fbp"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZbYXM0gAN3F"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leon-mqNAN5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3688be94-289f-4c15-b5c9-95ee91b3744e"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 53166588408365056.0000 - accuracy: 0.3051\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 21382080218791936.0000 - accuracy: 0.3338\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 18066638196703232.0000 - accuracy: 0.3362\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 15160321874329600.0000 - accuracy: 0.3395\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 14146242514780160.0000 - accuracy: 0.3436\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 12012931185115136.0000 - accuracy: 0.3417\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 10301765748523008.0000 - accuracy: 0.3462\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 8650734149042176.0000 - accuracy: 0.3515\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 7613427069485056.0000 - accuracy: 0.3553\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 7112833061879808.0000 - accuracy: 0.3504\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 5695628071927808.0000 - accuracy: 0.3625\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 5028101033558016.0000 - accuracy: 0.3606\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 4601496964431872.0000 - accuracy: 0.3610\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 3600971447926784.0000 - accuracy: 0.3678\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 3088195034021888.0000 - accuracy: 0.3655\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 2839868346466304.0000 - accuracy: 0.3594\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1906494106763264.0000 - accuracy: 0.3165\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1162420953284608.0000 - accuracy: 0.3073\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 722752868712448.0000 - accuracy: 0.3352\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 429240340185088.0000 - accuracy: 0.3543\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 196396405751808.0000 - accuracy: 0.3631\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 168152281382912.0000 - accuracy: 0.3583\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 103060533673984.0000 - accuracy: 0.3564\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 61461057503232.0000 - accuracy: 0.3312\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 4211183714304.0000 - accuracy: 0.3372\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 4904515534848.0000 - accuracy: 0.3360\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 7199538544640.0000 - accuracy: 0.3364\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 2285121306624.0000 - accuracy: 0.3346\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 4542336335872.0000 - accuracy: 0.3320\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 5112009326592.0000 - accuracy: 0.3232\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7733 - accuracy: 0.3171\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7726 - accuracy: 0.3171\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7722 - accuracy: 0.3171\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7720 - accuracy: 0.3171\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7718 - accuracy: 0.3171\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7717 - accuracy: 0.3171\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7716 - accuracy: 0.3171\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7715 - accuracy: 0.3171\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7714 - accuracy: 0.3171\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7713 - accuracy: 0.3171\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7713 - accuracy: 0.3171\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7712 - accuracy: 0.3171\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7712 - accuracy: 0.3171\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7711 - accuracy: 0.3171\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7711 - accuracy: 0.3171\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7711 - accuracy: 0.3171\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7711 - accuracy: 0.3171\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7709 - accuracy: 0.3171\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7710 - accuracy: 0.3171\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda32fe2d90>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWrgg1Z_AN73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa1dca2-f1a7-461d-8974-9fc39c6442a3"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.3170088827610016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57yD_vMjAN-I"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3zRGMB9Vfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b644f41d-147f-4fc1-a9b1-ec9a9248f862"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.00      0.00      0.00      1191\n",
            "           4       1.00      0.00      0.00      1904\n",
            "           5       0.32      1.00      0.48      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.32      7208\n",
            "   macro avg       0.15      0.11      0.05      7208\n",
            "weighted avg       0.36      0.32      0.15      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSBNFhI_BRaG",
        "outputId": "e576bc6c-1b93-43f5-f5dd-62de3c98ed1a"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5000809173077014"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfjt-sZDnVkl"
      },
      "source": [
        "# 3 Layer RELU Model with SGD Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvCz0D48nVkt"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQBCQQbknVkt"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqqKIyvKnVkt",
        "outputId": "03701509-ebc5-4c36-f3d8-465010a43b5a"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0097\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.0096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda273963d0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LhLpnZhnVku",
        "outputId": "459bfc5c-ab88-4bcb-9b84-058fc336592d"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.00957269687205553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75EdgYDLnVku"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP4wd3znnVku",
        "outputId": "cd951281-7dc1-4a1d-e99b-6079e90d7968"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      1.00      0.02        69\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.00      0.00      0.00      1191\n",
            "           4       0.00      0.00      0.00      1904\n",
            "           5       0.00      0.00      0.00      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.00      0.00      0.00       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.01      7208\n",
            "   macro avg       0.00      0.11      0.00      7208\n",
            "weighted avg       0.00      0.01      0.00      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bibGTCI6BUY7",
        "outputId": "fc448e4b-107c-41e4-cd03-3bc2d0f195f2"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEwBQj_5oCv_"
      },
      "source": [
        "# 3 Layer TANH Model with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwt-Mh4ToCv_"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB3ch_PqoCv_"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CuzSe2HoCv_",
        "outputId": "f8a061c4-3c7b-422a-f475-eff9dea07e14"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.7665 - accuracy: 0.3849\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4231 - accuracy: 0.4601\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3506 - accuracy: 0.4843\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3023 - accuracy: 0.5049\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2679 - accuracy: 0.5181\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2386 - accuracy: 0.5313\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2151 - accuracy: 0.5449\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1958 - accuracy: 0.5492\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1789 - accuracy: 0.5554\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1640 - accuracy: 0.5628\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1518 - accuracy: 0.5653\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1391 - accuracy: 0.5737\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1279 - accuracy: 0.5741\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1151 - accuracy: 0.5796\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1084 - accuracy: 0.5807\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1002 - accuracy: 0.5853\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0942 - accuracy: 0.5868\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0870 - accuracy: 0.5865\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0807 - accuracy: 0.5900\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0763 - accuracy: 0.5891\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0686 - accuracy: 0.5916\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0673 - accuracy: 0.5891\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0615 - accuracy: 0.5936\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0558 - accuracy: 0.5946\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0528 - accuracy: 0.5937\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0496 - accuracy: 0.5956\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0445 - accuracy: 0.5942\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0413 - accuracy: 0.5957\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0376 - accuracy: 0.5988\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0373 - accuracy: 0.5961\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0349 - accuracy: 0.5980\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0301 - accuracy: 0.5984\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0264 - accuracy: 0.5977\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0255 - accuracy: 0.5996\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0245 - accuracy: 0.6007\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0227 - accuracy: 0.6012\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0190 - accuracy: 0.5993\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0189 - accuracy: 0.5989\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0167 - accuracy: 0.5991\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0160 - accuracy: 0.6015\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0139 - accuracy: 0.6005\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0130 - accuracy: 0.5998\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0100 - accuracy: 0.6032\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0087 - accuracy: 0.6031\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0072 - accuracy: 0.6031\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0065 - accuracy: 0.6013\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0053 - accuracy: 0.6020\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0054 - accuracy: 0.6022\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0038 - accuracy: 0.6031\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0007 - accuracy: 0.6024\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0001 - accuracy: 0.6035\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9984 - accuracy: 0.6037\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9970 - accuracy: 0.6055\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9966 - accuracy: 0.6021\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9941 - accuracy: 0.6068\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9965 - accuracy: 0.6039\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9941 - accuracy: 0.6051\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9926 - accuracy: 0.6070\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9935 - accuracy: 0.6040\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9919 - accuracy: 0.6035\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9916 - accuracy: 0.6022\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9896 - accuracy: 0.6046\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9887 - accuracy: 0.6074\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9893 - accuracy: 0.6026\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9895 - accuracy: 0.6043\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9882 - accuracy: 0.6066\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9869 - accuracy: 0.6042\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9854 - accuracy: 0.6056\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9836 - accuracy: 0.6083\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9825 - accuracy: 0.6075\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9851 - accuracy: 0.6070\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9836 - accuracy: 0.6068\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9819 - accuracy: 0.6064\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9832 - accuracy: 0.6068\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9823 - accuracy: 0.6080\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9804 - accuracy: 0.6067\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9807 - accuracy: 0.6071\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9813 - accuracy: 0.6091\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9783 - accuracy: 0.6084\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9787 - accuracy: 0.6060\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9792 - accuracy: 0.6065\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9792 - accuracy: 0.6074\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9789 - accuracy: 0.6074\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9765 - accuracy: 0.6060\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9773 - accuracy: 0.6095\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9765 - accuracy: 0.6065\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9770 - accuracy: 0.6065\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9762 - accuracy: 0.6101\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9768 - accuracy: 0.6057\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9763 - accuracy: 0.6063\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9736 - accuracy: 0.6078\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9748 - accuracy: 0.6077\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9726 - accuracy: 0.6075\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9729 - accuracy: 0.6078\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9758 - accuracy: 0.6049\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9736 - accuracy: 0.6075\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9714 - accuracy: 0.6085\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9717 - accuracy: 0.6077\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9719 - accuracy: 0.6092\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.9715 - accuracy: 0.6071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda27236a90>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3HTw5OnoCwA",
        "outputId": "1b2b793c-d44d-41c0-a8e8-e592b1ae6087"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6102941036224365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OChsnv-JoCwA"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRrBjntRoCwA",
        "outputId": "8aed423c-f0b3-4b41-e231-f6920c4ada1d"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg , y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.17      0.25        69\n",
            "           1       0.61      0.40      0.48       319\n",
            "           2       0.69      0.19      0.30       117\n",
            "           3       0.58      0.70      0.64      1191\n",
            "           4       0.56      0.63      0.59      1904\n",
            "           5       0.64      0.68      0.66      2283\n",
            "           9       0.74      0.36      0.48       412\n",
            "          10       0.69      0.61      0.65       573\n",
            "          11       0.66      0.40      0.50       340\n",
            "\n",
            "    accuracy                           0.61      7208\n",
            "   macro avg       0.63      0.46      0.51      7208\n",
            "weighted avg       0.62      0.61      0.60      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ffDkK9BY9F",
        "outputId": "9df49008-f321-493c-9ee7-9e05fcc99596"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7018652944564027"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmU2ltfcoCwA"
      },
      "source": [
        "# 3 Layer TANH Model with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTewdGg2oCwB"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"tanh\"))\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfFBXUeOoCwB"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wby7ry1oCwB",
        "outputId": "0cba4654-4f15-460d-d756-c58c6a8db04c"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 2.0179 - accuracy: 0.3302\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6485 - accuracy: 0.3983\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5581 - accuracy: 0.4206\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5159 - accuracy: 0.4340\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4853 - accuracy: 0.4388\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4610 - accuracy: 0.4533\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4403 - accuracy: 0.4668\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4216 - accuracy: 0.4739\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4051 - accuracy: 0.4815\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3899 - accuracy: 0.4871\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3753 - accuracy: 0.4946\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3621 - accuracy: 0.4993\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3498 - accuracy: 0.5096\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3381 - accuracy: 0.5133\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3266 - accuracy: 0.5204\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3169 - accuracy: 0.5261\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3065 - accuracy: 0.5275\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2971 - accuracy: 0.5318\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2876 - accuracy: 0.5363\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2792 - accuracy: 0.5380\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2709 - accuracy: 0.5420\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2627 - accuracy: 0.5431\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2550 - accuracy: 0.5485\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2479 - accuracy: 0.5487\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2414 - accuracy: 0.5537\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2341 - accuracy: 0.5546\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2276 - accuracy: 0.5580\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2212 - accuracy: 0.5579\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2152 - accuracy: 0.5576\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2096 - accuracy: 0.5594\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2038 - accuracy: 0.5622\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1986 - accuracy: 0.5631\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1934 - accuracy: 0.5652\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1877 - accuracy: 0.5663\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1828 - accuracy: 0.5677\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1773 - accuracy: 0.5689\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1731 - accuracy: 0.5698\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1689 - accuracy: 0.5693\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1638 - accuracy: 0.5732\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1601 - accuracy: 0.5746\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1560 - accuracy: 0.5744\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1513 - accuracy: 0.5772\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1473 - accuracy: 0.5784\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1431 - accuracy: 0.5792\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1402 - accuracy: 0.5804\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1360 - accuracy: 0.5823\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1317 - accuracy: 0.5828\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1294 - accuracy: 0.5833\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1256 - accuracy: 0.5865\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1227 - accuracy: 0.5874\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1195 - accuracy: 0.5873\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1162 - accuracy: 0.5867\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1125 - accuracy: 0.5888\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1095 - accuracy: 0.5910\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1069 - accuracy: 0.5884\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1029 - accuracy: 0.5903\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1017 - accuracy: 0.5898\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0982 - accuracy: 0.5898\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0966 - accuracy: 0.5895\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0941 - accuracy: 0.5911\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0909 - accuracy: 0.5912\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0882 - accuracy: 0.5916\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0863 - accuracy: 0.5943\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0848 - accuracy: 0.5926\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0812 - accuracy: 0.5941\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0790 - accuracy: 0.5964\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0775 - accuracy: 0.5935\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0741 - accuracy: 0.5949\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0726 - accuracy: 0.5921\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0712 - accuracy: 0.5967\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0684 - accuracy: 0.5970\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0653 - accuracy: 0.5994\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0646 - accuracy: 0.5979\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0635 - accuracy: 0.5959\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0603 - accuracy: 0.5976\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0598 - accuracy: 0.5989\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0579 - accuracy: 0.5994\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0564 - accuracy: 0.5970\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0541 - accuracy: 0.6004\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0525 - accuracy: 0.6007\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0510 - accuracy: 0.6005\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0494 - accuracy: 0.6019\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0489 - accuracy: 0.6000\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0460 - accuracy: 0.6004\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0454 - accuracy: 0.6028\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0449 - accuracy: 0.6025\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0429 - accuracy: 0.6038\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0413 - accuracy: 0.6029\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0395 - accuracy: 0.6022\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0391 - accuracy: 0.6015\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0385 - accuracy: 0.6014\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0355 - accuracy: 0.6033\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0347 - accuracy: 0.6063\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0327 - accuracy: 0.6047\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0327 - accuracy: 0.6052\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0310 - accuracy: 0.6045\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0306 - accuracy: 0.6039\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0287 - accuracy: 0.6041\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0279 - accuracy: 0.6050\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0255 - accuracy: 0.6070\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda2711ffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOHyVmPUoCwB",
        "outputId": "acb3ff73-568e-42e5-a601-27e24da1ffd4"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5979467034339905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaVK0Pq3oCwB"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AKfmLD8oCwC",
        "outputId": "75c7a7c6-0173-44aa-fc98-eda434ef2ef3"
      },
      "source": [
        "res = tf.math.confusion_matrix(y_test_arg, y_pred_arg)\n",
        "print(res)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  11    0    0   19   26   12    0    0    0    0    0    1]\n",
            " [   0   85    4   33   51  128    0    0    0    1    0   17]\n",
            " [   0    0   26   60   25    6    0    0    0    0    0    0]\n",
            " [   2    1    5  819  228  114    0    0    0    9    8    5]\n",
            " [   1    0    3  224 1187  375    0    0    0   75    8   31]\n",
            " [   6    0    0  245  323 1630    0    0    0   31   17   31]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    1   29   59   96    0    0    0  208   13    6]\n",
            " [   2    0    0   17   98  195    0    0    0    9  252    0]\n",
            " [   1    0    0   47   74  100    0    0    0   26    0   92]], shape=(12, 12), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJiLcn5aoCwC",
        "outputId": "1bd56c34-bff8-4856-d136-2691d3e350f9"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.16      0.24        69\n",
            "           1       0.99      0.27      0.42       319\n",
            "           2       0.67      0.22      0.33       117\n",
            "           3       0.55      0.69      0.61      1191\n",
            "           4       0.57      0.62      0.60      1904\n",
            "           5       0.61      0.71      0.66      2283\n",
            "           9       0.58      0.50      0.54       412\n",
            "          10       0.85      0.44      0.58       573\n",
            "          11       0.50      0.27      0.35       340\n",
            "\n",
            "    accuracy                           0.60      7208\n",
            "   macro avg       0.64      0.43      0.48      7208\n",
            "weighted avg       0.62      0.60      0.59      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWeaKQTmBhIm",
        "outputId": "a95af4a4-5467-439a-890f-4c97f083c7fa"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6864066336959342"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTMquuFKoCwC"
      },
      "source": [
        "# 3 Layer Sigmoid with ADAM Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAcyiVkzoCwC"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBtE-6TwoCwD"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzPD-hZsoCwD",
        "outputId": "3ebcae59-5eb6-4a03-e212-c013e5616ca6"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6759 - accuracy: 0.3562\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5648 - accuracy: 0.3979\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5167 - accuracy: 0.4146\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4816 - accuracy: 0.4298\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4529 - accuracy: 0.4465\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4282 - accuracy: 0.4574\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4067 - accuracy: 0.4673\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3885 - accuracy: 0.4766\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3702 - accuracy: 0.4850\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3536 - accuracy: 0.4900\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3408 - accuracy: 0.4960\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3256 - accuracy: 0.5013\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3133 - accuracy: 0.5087\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.3027 - accuracy: 0.5137\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2910 - accuracy: 0.5160\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2819 - accuracy: 0.5205\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2705 - accuracy: 0.5224\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2615 - accuracy: 0.5270\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2537 - accuracy: 0.5305\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2456 - accuracy: 0.5318\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2384 - accuracy: 0.5356\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2311 - accuracy: 0.5356\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2246 - accuracy: 0.5408\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2173 - accuracy: 0.5442\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2120 - accuracy: 0.5425\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2050 - accuracy: 0.5457\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.2009 - accuracy: 0.5455\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1942 - accuracy: 0.5486\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1902 - accuracy: 0.5512\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1844 - accuracy: 0.5520\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1794 - accuracy: 0.5524\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1754 - accuracy: 0.5546\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1714 - accuracy: 0.5535\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1662 - accuracy: 0.5572\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1628 - accuracy: 0.5591\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1578 - accuracy: 0.5625\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1542 - accuracy: 0.5595\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1507 - accuracy: 0.5627\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1476 - accuracy: 0.5634\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1434 - accuracy: 0.5661\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1402 - accuracy: 0.5669\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1372 - accuracy: 0.5652\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1331 - accuracy: 0.5687\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1292 - accuracy: 0.5691\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1276 - accuracy: 0.5694\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1249 - accuracy: 0.5702\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1238 - accuracy: 0.5723\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1186 - accuracy: 0.5707\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1148 - accuracy: 0.5742\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1138 - accuracy: 0.5737\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1124 - accuracy: 0.5727\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1091 - accuracy: 0.5755\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1045 - accuracy: 0.5755\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1022 - accuracy: 0.5787\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.1022 - accuracy: 0.5744\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0980 - accuracy: 0.5781\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0959 - accuracy: 0.5788\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0952 - accuracy: 0.5794\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0904 - accuracy: 0.5799\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0903 - accuracy: 0.5808\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0858 - accuracy: 0.5811\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0861 - accuracy: 0.5829\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0847 - accuracy: 0.5837\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0815 - accuracy: 0.5822\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0795 - accuracy: 0.5835\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0790 - accuracy: 0.5856\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0759 - accuracy: 0.5831\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0750 - accuracy: 0.5852\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0736 - accuracy: 0.5865\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0691 - accuracy: 0.5874\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0679 - accuracy: 0.5851\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0687 - accuracy: 0.5871\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0654 - accuracy: 0.5887\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0640 - accuracy: 0.5872\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0613 - accuracy: 0.5881\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0599 - accuracy: 0.5909\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0577 - accuracy: 0.5886\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0577 - accuracy: 0.5903\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0569 - accuracy: 0.5904\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0538 - accuracy: 0.5908\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0510 - accuracy: 0.5923\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0498 - accuracy: 0.5942\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0527 - accuracy: 0.5904\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0494 - accuracy: 0.5925\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0453 - accuracy: 0.5936\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0460 - accuracy: 0.5943\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0450 - accuracy: 0.5918\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0417 - accuracy: 0.5950\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0427 - accuracy: 0.5948\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0402 - accuracy: 0.5963\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0398 - accuracy: 0.5953\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0384 - accuracy: 0.5963\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0359 - accuracy: 0.5964\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0382 - accuracy: 0.5959\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0350 - accuracy: 0.5952\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0332 - accuracy: 0.5980\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0337 - accuracy: 0.5968\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0333 - accuracy: 0.5960\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0313 - accuracy: 0.5942\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.0301 - accuracy: 0.5961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda26ee5490>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7hvD_3yoCwD",
        "outputId": "ab35227a-93b6-46cc-eaf5-5a6154a7f5b9"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5826858878135681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hx_OdNloCwD"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSBLWwlvoCwE",
        "outputId": "e359cafe-9297-4088-cba7-3c909cb54f57"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.16      0.25        69\n",
            "           1       0.94      0.35      0.51       319\n",
            "           2       0.44      0.18      0.25       117\n",
            "           3       0.56      0.69      0.62      1191\n",
            "           4       0.59      0.57      0.58      1904\n",
            "           5       0.63      0.66      0.64      2283\n",
            "           9       0.49      0.40      0.44       412\n",
            "          10       0.48      0.71      0.58       573\n",
            "          11       0.55      0.21      0.31       340\n",
            "\n",
            "    accuracy                           0.58      7208\n",
            "   macro avg       0.59      0.44      0.46      7208\n",
            "weighted avg       0.59      0.58      0.57      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ4ijN6iBlgN",
        "outputId": "83520013-4dfe-4644-9249-e5063436f036"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6888239501211972"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoxShjvjoCwE"
      },
      "source": [
        "# 3 Layer Sigmoid with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDvouOWkoCwE"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_np.shape[1], activation=\"sigmoid\"))\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "model.add(Dense(12, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAu-aWkhoCwE"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa8DwprvoCwE",
        "outputId": "743e2629-81cc-41c5-cbea-7cbb3f700708"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.8172 - accuracy: 0.3210\n",
            "Epoch 2/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6909 - accuracy: 0.3530\n",
            "Epoch 3/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6663 - accuracy: 0.3608\n",
            "Epoch 4/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6529 - accuracy: 0.3643\n",
            "Epoch 5/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6435 - accuracy: 0.3664\n",
            "Epoch 6/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6363 - accuracy: 0.3686\n",
            "Epoch 7/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6303 - accuracy: 0.3711\n",
            "Epoch 8/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6248 - accuracy: 0.3721\n",
            "Epoch 9/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6196 - accuracy: 0.3754\n",
            "Epoch 10/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6150 - accuracy: 0.3775\n",
            "Epoch 11/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6105 - accuracy: 0.3793\n",
            "Epoch 12/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6062 - accuracy: 0.3802\n",
            "Epoch 13/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.6019 - accuracy: 0.3806\n",
            "Epoch 14/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5979 - accuracy: 0.3815\n",
            "Epoch 15/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5937 - accuracy: 0.3843\n",
            "Epoch 16/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5894 - accuracy: 0.3837\n",
            "Epoch 17/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5854 - accuracy: 0.3859\n",
            "Epoch 18/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5813 - accuracy: 0.3866\n",
            "Epoch 19/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5775 - accuracy: 0.3862\n",
            "Epoch 20/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5736 - accuracy: 0.3881\n",
            "Epoch 21/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5697 - accuracy: 0.3873\n",
            "Epoch 22/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5659 - accuracy: 0.3899\n",
            "Epoch 23/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5622 - accuracy: 0.3915\n",
            "Epoch 24/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5587 - accuracy: 0.3907\n",
            "Epoch 25/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5549 - accuracy: 0.3931\n",
            "Epoch 26/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5512 - accuracy: 0.3943\n",
            "Epoch 27/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5479 - accuracy: 0.3951\n",
            "Epoch 28/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5443 - accuracy: 0.3952\n",
            "Epoch 29/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5411 - accuracy: 0.3961\n",
            "Epoch 30/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5381 - accuracy: 0.3970\n",
            "Epoch 31/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5348 - accuracy: 0.3993\n",
            "Epoch 32/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5318 - accuracy: 0.4001\n",
            "Epoch 33/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5288 - accuracy: 0.4039\n",
            "Epoch 34/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5258 - accuracy: 0.4093\n",
            "Epoch 35/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5230 - accuracy: 0.4102\n",
            "Epoch 36/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5200 - accuracy: 0.4141\n",
            "Epoch 37/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5174 - accuracy: 0.4153\n",
            "Epoch 38/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5148 - accuracy: 0.4187\n",
            "Epoch 39/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5121 - accuracy: 0.4196\n",
            "Epoch 40/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5095 - accuracy: 0.4192\n",
            "Epoch 41/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5069 - accuracy: 0.4236\n",
            "Epoch 42/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5043 - accuracy: 0.4279\n",
            "Epoch 43/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.5019 - accuracy: 0.4289\n",
            "Epoch 44/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4997 - accuracy: 0.4326\n",
            "Epoch 45/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4973 - accuracy: 0.4324\n",
            "Epoch 46/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4950 - accuracy: 0.4340\n",
            "Epoch 47/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4930 - accuracy: 0.4384\n",
            "Epoch 48/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4906 - accuracy: 0.4373\n",
            "Epoch 49/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4884 - accuracy: 0.4406\n",
            "Epoch 50/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4862 - accuracy: 0.4415\n",
            "Epoch 51/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4840 - accuracy: 0.4440\n",
            "Epoch 52/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4823 - accuracy: 0.4439\n",
            "Epoch 53/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4801 - accuracy: 0.4466\n",
            "Epoch 54/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4780 - accuracy: 0.4467\n",
            "Epoch 55/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4762 - accuracy: 0.4494\n",
            "Epoch 56/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4741 - accuracy: 0.4482\n",
            "Epoch 57/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4723 - accuracy: 0.4507\n",
            "Epoch 58/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4704 - accuracy: 0.4510\n",
            "Epoch 59/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4685 - accuracy: 0.4524\n",
            "Epoch 60/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4668 - accuracy: 0.4520\n",
            "Epoch 61/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4649 - accuracy: 0.4533\n",
            "Epoch 62/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4631 - accuracy: 0.4535\n",
            "Epoch 63/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4612 - accuracy: 0.4559\n",
            "Epoch 64/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4593 - accuracy: 0.4570\n",
            "Epoch 65/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4578 - accuracy: 0.4581\n",
            "Epoch 66/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4559 - accuracy: 0.4571\n",
            "Epoch 67/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4542 - accuracy: 0.4602\n",
            "Epoch 68/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4527 - accuracy: 0.4600\n",
            "Epoch 69/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4510 - accuracy: 0.4613\n",
            "Epoch 70/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4493 - accuracy: 0.4622\n",
            "Epoch 71/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4477 - accuracy: 0.4629\n",
            "Epoch 72/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4460 - accuracy: 0.4621\n",
            "Epoch 73/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4444 - accuracy: 0.4639\n",
            "Epoch 74/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4429 - accuracy: 0.4648\n",
            "Epoch 75/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4414 - accuracy: 0.4645\n",
            "Epoch 76/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4395 - accuracy: 0.4663\n",
            "Epoch 77/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4382 - accuracy: 0.4634\n",
            "Epoch 78/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4364 - accuracy: 0.4674\n",
            "Epoch 79/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4351 - accuracy: 0.4690\n",
            "Epoch 80/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4334 - accuracy: 0.4678\n",
            "Epoch 81/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4322 - accuracy: 0.4677\n",
            "Epoch 82/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4305 - accuracy: 0.4683\n",
            "Epoch 83/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4290 - accuracy: 0.4708\n",
            "Epoch 84/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4275 - accuracy: 0.4708\n",
            "Epoch 85/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4261 - accuracy: 0.4727\n",
            "Epoch 86/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4246 - accuracy: 0.4728\n",
            "Epoch 87/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4230 - accuracy: 0.4741\n",
            "Epoch 88/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4216 - accuracy: 0.4734\n",
            "Epoch 89/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4202 - accuracy: 0.4749\n",
            "Epoch 90/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4187 - accuracy: 0.4763\n",
            "Epoch 91/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4175 - accuracy: 0.4756\n",
            "Epoch 92/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4159 - accuracy: 0.4766\n",
            "Epoch 93/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4147 - accuracy: 0.4745\n",
            "Epoch 94/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4132 - accuracy: 0.4770\n",
            "Epoch 95/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4118 - accuracy: 0.4797\n",
            "Epoch 96/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4104 - accuracy: 0.4764\n",
            "Epoch 97/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4091 - accuracy: 0.4791\n",
            "Epoch 98/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4078 - accuracy: 0.4793\n",
            "Epoch 99/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4061 - accuracy: 0.4804\n",
            "Epoch 100/100\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 1.4051 - accuracy: 0.4815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda20572ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PB-30x4oCwF",
        "outputId": "8a9e87a9-5b89-4865-b2ed-5c5022e9eedd"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.4732241928577423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMpZmtxloCwF"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_arg = tf.argmax(y_test, 1)\n",
        "y_pred_arg = tf.argmax(y_pred, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBft0k9EoCwF",
        "outputId": "40bb5b45-2672-4a86-bb33-10ba1a510ebc"
      },
      "source": [
        "print(\"Classification Report:\")\n",
        "print()\n",
        "print(classification_report(y_test_arg, y_pred_arg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        69\n",
            "           1       0.95      0.18      0.30       319\n",
            "           2       0.00      0.00      0.00       117\n",
            "           3       0.46      0.72      0.56      1191\n",
            "           4       0.47      0.31      0.37      1904\n",
            "           5       0.46      0.76      0.57      2283\n",
            "           9       0.00      0.00      0.00       412\n",
            "          10       0.67      0.32      0.43       573\n",
            "          11       0.00      0.00      0.00       340\n",
            "\n",
            "    accuracy                           0.47      7208\n",
            "   macro avg       0.33      0.25      0.25      7208\n",
            "weighted avg       0.44      0.47      0.42      7208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pUIbVNfBob2",
        "outputId": "9c460721-b496-4d38-e37e-f8264410b0c2"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred_arg)\n",
        "  return roc_auc_score(y_test,  y_pred, average=average)\n",
        "multiclass_roc_auc_score(y_test_arg, y_pred_arg, average=\"macro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5865609716028897"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ornKPcOjkkf"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLyriul3NdVB"
      },
      "source": [
        "![NN2 100 EPOC.png](data:image/png;base64,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)![NN1 20 Epoc.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ouW0UX3jS-I"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oAGggN4jVR-"
      },
      "source": [
        "When creating the Deep Learning model, I used three different activation functions:  RELU, Tanh, and Sigmoid.\n",
        "\n",
        "Each model only consisted of three layers, with two different optimizers applied for each model.  The optimizers are:  ADAM & SGD\n",
        "\n",
        "Once I was able to determine which activation function and which optimizer provided the best results, I had increased the amount of epochs from 20 to 100.  I also decreased the batch size in the second table to see if it made a difference in accuracy.\n",
        "\n",
        "Overall, it made a very small difference.  The most gain a model received was TANH Model with the SGD Optimizer, rising from 0.50 to 0.58 accuracy.  \n",
        "\n",
        "The highest accuracy I was able to get was 0.70 from the TANH Model with ADAM Optimizer with the Batch Size set at 64 with an EPOC level at 100.  \n"
      ]
    }
  ]
}